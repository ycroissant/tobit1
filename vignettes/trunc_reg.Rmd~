---
title: zerotrunc, an R Package for Estimating tobit models on truncated or on censored samples
author: Yves Croissant
date: 2021/03/10
output: 
  html_document:
    toc: true
    toc_float: true
  pdf_document:
    number_sections: true
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{zerotrunc: an R package for tobit models}
  %\VignetteEngine{knitr::rmarkdown}
---

# Modèle censuré

## Version brute

$$
\ln L(\beta, \sigma) = 
\sum_{n = 1} ^ {N_0} \ln \Phi \left(- \beta ^ \top x_n / \sigma\right) -
\frac{N_1}{2} \ln 2\pi - N_1\ln \sigma -
\frac{1}{2}\sum_{n = N_0 + 1}^{N} \left(\frac{y_n -\beta^\top x_n}{\sigma}\right) ^ 2
$$

$$
\mu_n = \mu\left(-\beta ^ \top x_n / \sigma\right)
$$

$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial \ln L}{\partial \beta} &=& \displaystyle
\frac{1}{\sigma ^ 2}\left[\sum_{n = N_0 + 1}^{N} (y_n - \beta ^ \top
x_n)x_n- \sigma \sum_{n = 1} ^ {N_0} \mu_n x_n\right]\\
\displaystyle\frac{\partial \ln L}{\partial \sigma} &=&  \displaystyle
- \frac{1}{\sigma ^ 3}
\left[N_1 \sigma ^ 2 - \sum_{n=N_0 + 1} ^ N (y_n - \beta ^ \top x_n) ^ 2- \sigma \sum_{n = 1} ^ {N_0}\mu_n
\beta ^ \top x_n \right]
\end{array}
\right.
$$


$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial^2 \ln L}{\partial \beta \partial \beta ^ \top} &=&\displaystyle
-\frac{1}{\sigma ^ 2} \sum_{n = 1}^{N_0}\mu_n\left(\mu_n -
\beta^\top x_n/\sigma\right)x_n x_n ^ \top -
\frac{1}{\sigma ^ 2} \sum_{n = N_0+1}^N x_n x_n ^ \top \\
\displaystyle\frac{\partial^2 \ln L}{\partial \beta \partial \sigma} &=&\displaystyle
\frac{1}{\sigma ^ 2}\sum_{n = 1} ^ {N_0} \mu_n\left[1 + \beta ^
\top x_n/\sigma\left(\mu_n- \beta^\top
x_n/\sigma\right)\right]x_n -
\frac{2}{\sigma ^ 3} \sum_{n = N_0 + 1}^N (y_n - \beta^\top x_n)x_n\\
\displaystyle\frac{\partial^2 \ln L}{\partial \sigma ^ 2} &=&\displaystyle
- \frac{2}{\sigma ^ 3} \sum_{n = 1} ^ {N_0} \mu_n \beta ^ \top x_n -
\frac{1}{\sigma ^ 4} \sum_{n = 1} ^ {N_0} \mu_n \left(\mu_n -
\beta ^ \top x_n / \sigma\right)(\beta^\top x_n)^2 +
\frac{N_1}{\sigma ^ 2} - 
\frac{3}{\sigma ^ 4}\sum_{n = N_0 + 1} ^ N (y_n-\beta^\top x_n)^ 2
\end{array}
\right.
$$


## Olsen

$$
\ln L = \sum_{n = 1} ^ {N_1} \ln \Phi(-\gamma^\top x_n) -
\frac{N_1}{2}\ln 2\pi + N_1 \ln \theta - \frac{1}{2}\sum_{n=N_0+1} ^ N 
(\theta y - \gamma ^ \top x_n) ^ 2
$$


$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial \ln L}{\partial \gamma} &=& \displaystyle
- \sum_{n = 1} ^ {N_0} \mu_n x_n + \sum_{n = 1} (\theta y - \gamma^\top
  x_n)x_n\\
\displaystyle\frac{\partial \ln L}{\partial \theta} &=& \displaystyle
\frac{N_1}{\theta} -
  \sum_{n = N_0 + 1} ^ N (\theta y  - \gamma^\top x_n) y_n
  \end{array}
\right.
$$


$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial ^ 2 \ln L}{\partial \gamma\partial \gamma
^ \top} &=& \displaystyle
- \sum_{n = 1} ^ {N_0} \mu_n (\mu_n - \gamma ^ \top x_n) x_n
x_n^\top - \sum_{n = N_0 + 1} ^ N x_n x_n^\top\\
\displaystyle\frac{\partial^2 \ln L}{\partial \gamma\partial \sigma}
&=& \displaystyle
\sum_{n = N_0+1} ^ N y_n x_n \\
\displaystyle\frac{\partial ^ 2 \ln L}{\partial \gamma ^ 2} &=&
\displaystyle - \frac{N_1}{\theta ^ 2} - \sum_{n = N_0 + 1} ^ N y_n ^
2
\end{array}
\right.
$$


# Modèle tronqué

## Version brute

$$
\ln L(\beta, \sigma) = - \frac{N}{2} \ln 2\pi - N\ln \sigma - \sum_n \ln
\Phi\left(\beta ^ \top x_n / \sigma\right) - \frac{1}{2}\sum_n \left(\frac{y_n -\beta^\top x_n}{\sigma}\right) ^ 2
$$

$$
\mu_n = \mu\left(\beta ^ \top x_n / \sigma\right)
$$

$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial \ln L}{\partial \beta} &=& \displaystyle
\frac{1}{\sigma ^ 2} \sum_n\left[y_n - \beta ^ \top x_n - 
\sigma \mu_n\right]x_n\\
\displaystyle\frac{\partial \ln L}{\partial \sigma} &=& \displaystyle
-\frac{1}{\sigma ^ 3}
\left[N \sigma ^ 2 - \sum_n (y_n - \beta^\top x_n) ^ 2 -
\sigma\sum_n\mu_n\beta^\top
x_n\right]
\end{array}
\right.
$$

$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial^2 \ln L}{\partial \beta \partial \beta ^ \top} &=&\displaystyle
\frac{1}{\sigma ^ 2}\sum_n
\left[- 1 + \mu_n\left(\mu_n + \beta ^ \top x_n / \sigma\right)\right]x_nx_n^\top\\
\displaystyle\frac{\partial^2 \ln L}{\partial \beta \partial \sigma} &=&\displaystyle
-\frac{2}{\sigma ^ 3} \sum_n(y_n - \beta ^ \top x_n)x_n +
\frac{1}{\sigma ^ 2} \sum_n \mu_n\left[1 - \frac{\beta^\top
x_n}{\sigma}\left(\mu_n + \beta ^ \top x_n / \sigma\right) \right]\\
\displaystyle\frac{\partial^2 \ln L}{\partial \sigma ^ 2} &=&\displaystyle
\frac{N}{\sigma ^ 2} - \frac{3}{\sigma ^ 4} \sum_n (y_n-\beta ^ \top
x_n) ^ 2 - \frac{2}{\sigma ^ 2} \sum_n \mu_n \left(\beta ^ \top x_n / \sigma\right) + 
\frac{1}{\sigma ^ 2} \sum_n \mu_n \left(\mu_n + \beta^\top
x_n/\sigma\right)
\left(\beta ^ \top x_n / \sigma\right) ^ 2
\end{array}
\right.
$$


# Olsen


$$
\ln L(\gamma, \theta) = - \frac{N}{2} \ln 2\pi + N\ln \theta - \sum_n \ln
\Phi(\gamma^\top x_n) - \frac{1}{2}\sum_n \left(\theta y_n - \gamma^\top x_n\right) ^ 2
$$

$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial \ln L}{\partial \theta} &=&  \frac{N}{\theta} - 
\sum_n \left(\theta y_n - \gamma^\top x_n\right) y_n \\
\displaystyle\frac{\partial \ln L}{\partial \gamma} &=&
 \sum_n\left[\left(\theta y_n - \gamma^\top x_n- \mu(\gamma^\top x_n)\right)\right] x_n
\end{array}
\right.
$$


$$
\left\{
\begin{array}{rcl}
\displaystyle\frac{\partial^2 \ln L}{\partial \beta \partial \beta ^ \top} &=&
\sum_n \left[ - 1 + \mu_n(\mu_n + \gamma ^ \top x_n)\right]x_n
x_n^\top \\
\displaystyle\frac{\partial^2 \ln L}{\partial \beta \partial \sigma} &=&
\sum_n y_n x_n \\
\displaystyle\frac{\partial^2 \ln L}{\partial \sigma ^ 2} &=&
-\frac{N}{\theta^2} - \sum_n y_n ^ 2
\end{array}
\right.
$$

\clearpage

## Olsen concentré

Solve the first order condition for $\sigma$\ :

$$
\frac{\sum_n y_n ^ 2}{N} \theta ^ 2 - \frac{\sum_n (\gamma ^ \top x_n)
y_n}{N}\theta - 1 = 0
$$

soit : $\hat{\sigma}^2_y = \frac{\sum_n y_n ^ 2}{N}$ 
et $\rho =  \frac{\sum_n (\gamma ^ \top x_n) y_n}{N}$

$$
\hat{\sigma}^2_y \theta ^ 2 - \rho\theta - 1 = 0
$$

$$
\Delta = \rho ^ 2 + 4 \hat{\sigma}^2_y
$$


$$
\theta(\gamma) = \frac{\rho + \sqrt{\rho ^ 2 + 4
\hat{\sigma}^2_y}}{2\hat{\sigma}_y ^ 2}
$$

Then consider the concentrated log-likelihood function\:

$$
\ln L^C(\gamma) = -\frac{N}{2} \ln 2\pi + N\ln \theta(\gamma) - \sum_n \ln
\Phi(\gamma^\top x_n) - \frac{1}{2}\sum_n \left(\theta(\gamma)y_n -
\gamma^\top x_n\right) ^ 2
$$


$$
\frac{\partial \theta}{\partial \rho}=\frac{\theta}{\sqrt{\rho ^ 2 + 4
\hat{\sigma}^2_y}}
$$


$$
\left.\frac{\partial \ln L}{\partial \gamma}\right|_{\theta} =
 \sum_n\left[\theta y_n -  \gamma^\top x_n - \mu(\gamma^\top x_n)
 \right] x_n
$$

$$
\frac{\partial \ln L}{\partial \gamma} =
\left.\frac{\partial \ln L}{\partial \gamma}\right|_{\theta} + 
  \frac{\partial \ln L}{\partial \theta}
  \frac{\theta}{\sqrt{\rho ^ 2 + 4
\hat{\sigma}^2_y}}
\frac{\sum_n y_n x_n}{N}
$$
